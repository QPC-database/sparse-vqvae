"""
Script to explore the effect of different alpha values on the sparse code
"""
import torch
import numpy as np
import matplotlib.pyplot as plt

from utils.pyfista_test import create_normalized_noised_inputs, load_real_inputs
import pandas as pd

from utils.pyfista import FISTA


def score_fn(Z):
    """
    We evaluate the sparse code's L0 norm, specifically the average L0 norm, the standard deviation and the top 99% value.
    :param Z: Sparse code to evaluate.
    :return: Float, Float, Float. L0 norm mean, L0 norm std, top 99% L0 norm value.
    """
    norm = torch.norm(Z, p=0, dim=0)
    return norm.mean(), norm.std(), norm.topk(int(len(norm)*0.01)).values.min()


def histogram_fn(run_name, name, Z, alpha):
    """
    Create and save an historgam of the sparse code values for given alpha
    """
    print('Doing histogram with experiment {} and alpha {}'.format(name, alpha))
    plt.hist(Z)
    plt.savefig('histograms/{}_{}_{}.png'.format(run_name, name, alpha))
    plt.close()


def create_alpha_graph_random_data(alphas, just_plot=False, sparsity_num=10):
    """
    Create an alpha/L0 norm graph on random data.
    Data is generated by sampling a random dictionary and creating the data and sampling sparsity_num atoms for create
    a linear combination of dictionary atoms.
    :param alphas: tuple of (start, end, denominator). The graph will be over a the range(start / denominator, end / denominator).
    :param just_plot: Bool. Use cached results if True, else recalculate results.
    :param sparsity_num: Sparsity value used to create the random data.
    """
    filename = 'alpha_search_random_data_sparsity_{}_alpahs-{},results'.format(sparsity_num, alphas)

    experiments = {
        'no_normalization': create_normalized_noised_inputs(False, False, sparsity_num),
        'd_normalization': create_normalized_noised_inputs(True, False, sparsity_num),
        'x_normalization': create_normalized_noised_inputs(False, True, sparsity_num),
        'full_normalization': create_normalized_noised_inputs(True, True, sparsity_num),
    }

    create_alpha_graph(experiments, filename, alphas, just_plot)


def create_alpha_graph_real_data(just_plot=False, alphas=(0.01, 2, 0.01)):
    """
        Create an alpha/L0 norm graph on real data and random dictionary.
        Data is generated by running an untrained encoder on real data. Results are calculated with respect to a random dictionary.
        :param just_plot: Bool. Use cached results if True, else recalculate results.
        :param alphas: tuple of (start, end, denominator). The graph will be over a the range(start / denominator, end / denominator).
        """
    filename = 'alpha_search_real_data_alphas-{}_results'.format(alphas)
    experiments = {
        'no_normalization': load_real_inputs(False, False),
        'd_normalization': load_real_inputs(True, False),
        'x_normalization': load_real_inputs(False, True),
        'full_normalization': load_real_inputs(True, True),
    }

    create_alpha_graph(experiments, filename, alphas, just_plot=just_plot)


def create_alpha_graph(experiments, filename, alphas, just_plot=False):
    """
    Save experiment results to CSV file and graph
    :param experiments: List of (data, dictionary) for experiments ('no_normalization', 'd_normalization', 'x_normalization', 'full_normalization')
    :param filename: filename for the CSV and graph
    :param alphas: tuple of (start, end, denominator). The graph will be over a the range(start / denominator, end / denominator).
    :param just_plot: just_plot: Bool. Use cached results if True, else recalculate results.
    """
    if not just_plot:
        with open('{}.csv'.format(filename), 'w') as f:
            title_row = 'Alpha,' \
                        'no_normalization_score,no_normalization_std,no_normalization_percentile,' \
                        'd_normalization_score,d_normalization_std,d_normalization_percentile,' \
                        'x_normalization_score,x_normalization_std,x_normalization_percentile,' \
                        'full_normalization_score,full_normalization_std,full_normalization_percentile\n'
            f.write(title_row)

        alphas = list([float(a) / alphas[2] for a in range(alphas[0], alphas[1])])
        for alpha in alphas:
            process_alpha(alpha, experiments, filename)

    create_result_graph(filename)


def process_alpha(alpha, experiments, filename):
    """
    Save experiment results to CSV file
    :param alpha: Value of alpha to run for
    :param experiments: List of (data, dictionary) for experiments ('no_normalization', 'd_normalization', 'x_normalization', 'full_normalization')
    :param filename: filename for the CSV
    """

    # Run experiments
    d_normalization_Z, full_normalization_Z, no_normalization_Z, x_normalization_Z = run_experiments(alpha, experiments)

    # Extract statistics. TODO: Turn output and input to dictionary
    d_normalization_percentile, d_normalization_score, d_normalization_std, \
    full_normalization_percentile, full_normalization_score, full_normalization_std, \
    no_normalization_percentile, no_normalization_score, no_normalization_std, \
    x_normalization_percentile, x_normalization_score, x_normalization_std = \
        calculate_statistics(d_normalization_Z, full_normalization_Z, no_normalization_Z, x_normalization_Z)

    # Create histograms
    histogram_fn(filename, 'no_normalization_Z', no_normalization_Z.view(-1), alpha)
    histogram_fn(filename, 'd_normalization_Z', d_normalization_Z.view(-1), alpha)
    histogram_fn(filename, 'x_normalization_Z', x_normalization_Z.view(-1), alpha)
    histogram_fn(filename, 'full_normalization_Z', full_normalization_Z.view(-1), alpha)

    # Create final row
    results_row = '{},{},{},{},{},{},{},{},{},{},{},{},{}\n'.format(alpha,
                                                                    no_normalization_score, no_normalization_std,
                                                                    no_normalization_percentile,
                                                                    d_normalization_score, d_normalization_std,
                                                                    d_normalization_percentile,
                                                                    x_normalization_score, x_normalization_std,
                                                                    x_normalization_percentile,
                                                                    full_normalization_score,
                                                                    full_normalization_std,
                                                                    full_normalization_percentile,
                                                                    )

    with open('{}.csv'.format(filename), 'a') as f:
        f.write(results_row)


def create_result_graph(filename):
    """
    Save experiment results to graph
    :param filename: filename to load the data from
    """

    data = pd.read_csv('{}.csv'.format(filename), sep=',')
    # plt.errorbar(data['Alpha'], data['no_normalization_score'], yerr=data['no_normalization_std'])
    plt.errorbar(data['Alpha'], data['d_normalization_score'], color='r')
    plt.errorbar(data['Alpha'], data['d_normalization_percentile'], color='r', linestyle='--')
    plt.errorbar(data['Alpha'], data['x_normalization_score'], color='g')
    plt.errorbar(data['Alpha'], data['x_normalization_percentile'], color='g', linestyle='--')
    plt.errorbar(data['Alpha'], data['full_normalization_score'], color='b')
    plt.errorbar(data['Alpha'], data['full_normalization_percentile'], color='b', linestyle='--')
    plt.legend(
        [
            'D normalization',
            'D 99% percentile',
            'X normalization',
            'X 99% percentile',
            'Full normalization',
            'Full 99% percentile'
        ]
    )
    plt.yscale('log')
    plt.xlabel('Alpha')
    plt.ylabel('Log norm0')
    plt.title('Alpha search graph for {}'.format(filename))
    plt.savefig('{}_scores_with_errorbars.png'.format(filename))


def calculate_statistics(d_normalization_Z, full_normalization_Z, no_normalization_Z, x_normalization_Z):
    """
    Calculates statistics for given Sparse Code coefficients
    :param d_normalization_Z: d_normalization experiment sparse code coefficients
    :param full_normalization_Z: full_normalization experiment sparse code coefficients
    :param no_normalization_Z: no_normalization experiment sparse code coefficients
    :param x_normalization_Z: x_normalization experiment sparse code coefficients
    :return: For each experiment: Value of the 99% percentile L0 norm, mean L0 norm, standard deviation of L0 norm
    """
    no_normalization_score, no_normalization_std, no_normalization_percentile = score_fn(no_normalization_Z)
    d_normalization_score, d_normalization_std, d_normalization_percentile = score_fn(d_normalization_Z)
    x_normalization_score, x_normalization_std, x_normalization_percentile = score_fn(x_normalization_Z)
    full_normalization_score, full_normalization_std, full_normalization_percentile = score_fn(full_normalization_Z)
    return \
        d_normalization_percentile, d_normalization_score, d_normalization_std, \
        full_normalization_percentile, full_normalization_score, full_normalization_std, \
        no_normalization_percentile, no_normalization_score, no_normalization_std, \
        x_normalization_percentile, x_normalization_score, x_normalization_std


def run_experiments(alpha, experiments):
    """
    Runs FISTA for given experimental data
    :param alpha: value of data to use for FISTA
    :param experiments: Dictionary with fista input and dictionary with names of the experiments.
        expects experiments: no_normalization, d_normalization, x_normalization, full_normalization

    :return: Sparse code coefficients found for the experiments in the order:
        d_normalization, full_normalization, no_normalization, x_normalization
    """
    no_normalization_Z, _ = FISTA(experiments['no_normalization'][0], experiments['no_normalization'][1], alpha, 0.01)
    d_normalization_Z, _ = FISTA(experiments['d_normalization'][0], experiments['d_normalization'][1], alpha, 0.01)
    x_normalization_Z, _ = FISTA(experiments['x_normalization'][0], experiments['x_normalization'][1], alpha, 0.01)
    full_normalization_Z, _ = FISTA(experiments['full_normalization'][0], experiments['full_normalization'][1], alpha, 0.01)
    return d_normalization_Z, full_normalization_Z, no_normalization_Z, x_normalization_Z


if __name__ == '__main__':
    # create_alpha_graph_random_data(just_plot=False, sparsity_num=5, alphas=(100, 300, 1000))
    create_alpha_graph_real_data(just_plot=False, alphas=(100, 300, 1000))
